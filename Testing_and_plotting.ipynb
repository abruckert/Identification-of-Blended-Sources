{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model / Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction and visualisation of the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.misc import imread, imresize\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense, Input\n",
    "from keras import applications\n",
    "from keras import optimizers\n",
    "\n",
    "PATH_TO_IMAGE = './path_to_vignet'\n",
    "\n",
    "#Building the model\n",
    "input_tensor = Input(shape=(116,116,3))\n",
    "base_model = applications.VGG16(weights='imagenet', include_top=False, input_tensor=input_tensor)\n",
    "\n",
    "# build the classifier model to put on top of the convolutional model\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.4))\n",
    "top_model.add(Dense(1024, activation = 'relu'))\n",
    "top_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=top_model(base_model.output))\n",
    "#Adding the weights to the model\n",
    "model.load_weights('./vgg16_weights_best.h5')\n",
    "\n",
    "\n",
    "img = imread(PATH_TO_IMAGE)\n",
    "plt.imshow(img)\n",
    "\n",
    "#Ensuring the image is the right size\n",
    "img = imresize(img, (116,116)).astype(\"float32\")\n",
    "#Add a dimension for a \"batch\" of 1 image\n",
    "#This can be adapted to predict batches of more than 1 image\n",
    "img_batch = preprocess_input(img[np.newaxis]) \n",
    "\n",
    "predictions = model.predict(img_batch)\n",
    "decoded_predictions= decode_predictions(predictions)\n",
    "\n",
    "for s, name, score in decoded_predictions[0]:\n",
    "    print(name, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the representation of an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = model.layers[0].input\n",
    "output = model.layers[-2].output\n",
    "base_model = Model(input, output)\n",
    "\n",
    "representation = base_model.predict(img_batch)\n",
    "print(\"shape of representation:\", representation.shape)\n",
    "print(\"proportion of zero valued axis: %0.3f\"\n",
    "      % np.mean(representation[0]==0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since computing image representations can be time consuming, we will use pre-computed representations\n",
    "#This is done using the process_images.py script\n",
    "\n",
    "import os\n",
    "paths = [\"images_resize/\" + path\n",
    "         for path in sorted(os.listdir(\"images_resize/\"))]\n",
    "\n",
    "import h5py\n",
    "\n",
    "# Load pre-calculated representations\n",
    "h5f = h5py.File('img_emb.h5','r')\n",
    "out_tensors = h5f['img_emb'][:]\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "img_emb_tsne = TSNE(perplexity=30).fit_transform(out_tensors)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(img_emb_tsne[:, 0], img_emb_tsne[:, 1]);\n",
    "plt.xticks(()); plt.yticks(());\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding thumnails of the original images at their TSNE location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "from scipy.misc import imread, imresize\n",
    "\n",
    "def imscatter(x, y, paths, ax=None, zoom=1, linewidth=0):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    x, y = np.atleast_1d(x, y)\n",
    "    artists = []\n",
    "    for x0, y0, p in zip(x, y, paths):\n",
    "        try:\n",
    "            im = imread(p)\n",
    "        except:\n",
    "            print(p)\n",
    "            continue\n",
    "        im = imresize(im,(224,224))\n",
    "        im = OffsetImage(im, zoom=zoom)\n",
    "        ab = AnnotationBbox(im, (x0, y0), xycoords='data',\n",
    "                            frameon=True, pad=0.1, \n",
    "                            bboxprops=dict(edgecolor='red',\n",
    "                                           linewidth=linewidth))\n",
    "        artists.append(ax.add_artist(ab))\n",
    "    ax.update_datalim(np.column_stack([x, y]))\n",
    "    ax.autoscale()\n",
    "    return artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(50, 50))\n",
    "imscatter(img_emb_tsne[:, 0], img_emb_tsne[:, 1], paths, zoom=0.5, ax=ax)\n",
    "plt.savefig('tsne.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual Search: finding similar images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(img):\n",
    "    plt.figure()\n",
    "    img = imread(img)\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 57\n",
    "\n",
    "def most_similar(idx, top_n=5):\n",
    "    dists = np.linalg.norm(out_tensors - out_tensors[idx], axis = 1)\n",
    "    sorted_dists = np.argsort(dists)\n",
    "    return sorted_dists[:top_n]\n",
    "\n",
    "sim = most_similar(idx)\n",
    "[display(paths[s]) for s in sim];"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
